
<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>https://dcreager.net/</id>
  <title>dcreager.net</title>
  <updated>2018-05-02T00:00:00Z</updated>
  <link rel="alternate" href="https://dcreager.net/"/>
  <link rel="self" href="https://dcreager.net/atom.xml"/>
  <author>
    <name>Douglas Creager</name>
    <uri>https://dcreager.net/</uri>
  </author>
  <entry>
    <id>tag:dcreager.net,2018-04-19:/git/workflows/</id>
    <title type="html">Clean git histories and code review workflows</title>
    <published>2018-04-19T00:00:00Z</published>
    <updated>2018-05-02T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/git/workflows/"/>
    <content type="html">
&lt;script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;

&lt;p&gt;A couple of recent tweets really resonated me.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://adityamukerjee.net/"&gt;Aditya&lt;/a&gt; started an interesting conversation:&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;If you&amp;#39;d asked me a few weeks ago whether I preferred squash-merges or merge commits, I&amp;#39;d have been somewhat ambivalent.&lt;br /&gt;&lt;br /&gt;After today, I&amp;#39;m pretty sold on squash-merge as the better strategy. It&amp;#39;s not without drawbacks, but on net, it&amp;#39;s still so much better to work with.&lt;/p&gt;&amp;mdash; Aditya Mukerjee (@chimeracoder) &lt;a href="https://twitter.com/chimeracoder/status/986376765567356928?ref_src=twsrc%5Etfw"&gt;April 17, 2018&lt;/a&gt;&lt;/blockquote&gt;

&lt;p&gt;I’ve always really liked having a “clean” history in the git logs of my
projects.  They look nicer!  There’s a real joy to running &lt;a href="https://git-scm.com/docs/git-log"&gt;&lt;code&gt;git log&lt;/code&gt;&lt;/a&gt; (or
even better, &lt;a href="https://git-scm.com/docs/git-log"&gt;&lt;code&gt;git log --graph --all&lt;/code&gt;&lt;/a&gt;!) on a project that’s
maintained a beautiful log.  There are a number of tangible benefits, too, which
&lt;a href="https://chris.beams.io/posts/git-commit/"&gt;others&lt;/a&gt; &lt;a href="https://www.git-tower.com/learn/git/ebook/en/command-line/appendix/best-practices"&gt;have&lt;/a&gt; &lt;a href="https://www.slideshare.net/TarinGamberini/commit-messages-goodpractices"&gt;described&lt;/a&gt; well enough that I
don’t need to repeat them here.&lt;/p&gt;

&lt;p&gt;More than that, though, for a long time I assumed that if you were using GitHub
pull requests, there was One True Way to produce a clean history, echoed by
&lt;a href="https://sevein.com/"&gt;Jesús&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Best merges to me are the fast-forward merges that bring a number of meaninful, atomic, functional and self-contained commits! Not always possible...&lt;/p&gt;&amp;mdash; Jesús García Crespo (@sevein) &lt;a href="https://twitter.com/sevein/status/986412919964368896?ref_src=twsrc%5Etfw"&gt;April 18, 2018&lt;/a&gt;&lt;/blockquote&gt;

&lt;p&gt;But recently, just like Aditya, I’ve had a change of heart!  I realized that I
was thinking about pull requests, and what they represent in terms of the final
commit log I’m aiming for, in the wrong way.  In this post I’ll describe the
come-to-Aditya moment that made me appreciate squash-commits.  And along the way
I’ll have described two workflows that make it easy to keep a clean history: one
that doesn’t use GitHub at all (and mimics how we did git-driven development
before GitHub existed), and one that does.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2018-03-27:/nel/intro/</id>
    <title type="html">Introducing Network Error Logging</title>
    <published>2018-03-27T00:00:00Z</published>
    <updated>2018-03-27T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/nel/intro/"/>
    <content type="html">
&lt;p&gt;Let’s say you’ve got a web site or REST service.  You have clients that send
requests to your server, which performs some interesting processing and sends
responses back.  The clients might be people using a browser, or native code in
a mobile app making requests on behalf of the user, or something more exotic.
But the overall picture is the same:&lt;/p&gt;

&lt;p&gt;&lt;img src="/nel/intro/service-flow.png" alt="request service flow" class="figure" /&gt;&lt;/p&gt;

&lt;p&gt;How do you monitor this service — especially when that annoying cloudy bit in
the middle is completely out of your control?&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2017-10-29:/shared-library-versions/</id>
    <title type="html">Shared library versions</title>
    <published>2017-10-29T00:00:00Z</published>
    <updated>2017-10-29T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/shared-library-versions/"/>
    <content type="html">
&lt;p&gt;Congratulations, you’ve written a software library!  You hope that lots of
people will find it useful, and will take it as a dependency when writing their
own software.  You know that at some point you’ll have to make changes to your
library, either to add features or to fix bugs.  Being a good maintainer, you
want to be as diligent as possible in telling your users what to expect as you
publish these changes.  Will they need to change their code in response to the
changes that you’ve made?  Have you retired features that they depend on?  Or
are the changes “safe”, presumably requiring no updates on their part?&lt;/p&gt;

&lt;p&gt;The traditional approach is to encode all of this information into an
easy-to-digest &lt;strong&gt;version number&lt;/strong&gt;.  Of course, nothing in this world is simple,
so there are a number of different systems for encoding compatibility
information into a version number.  And surprisingly, if you’re writing a shared
library for a compiled language like C or C++, there are (at least!) two
different versioning systems that you’ll need to learn.  In this post, we’re
going to look at these different systems, how they relate to each other, and how
to actually apply these version numbers to your library using a couple of common
build tools.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2017-08-10:/obligations/intro/</id>
    <title type="html">Introduction</title>
    <published>2017-08-10T00:00:00Z</published>
    <updated>2017-08-10T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/obligations/intro/"/>
    <content type="html">
&lt;p&gt;Programming languages have a lot of interesting ways to think about what you’re
allowed to do, and not allowed to do.  In a statically typed language, your
compiler will yell at you if you try to do something that’s not allowed, and a
lot of interesting PL research involves teaching your language and compiler to
disallow things in increasingly sophisticated ways.&lt;/p&gt;

&lt;p&gt;This is not limited to statically typed languages.  In a dynamically typed
language, your interpreter is just as invested in disallowing certain behaviors.
It’s just that the enforcement happens while your program is running!&lt;/p&gt;

&lt;p&gt;Someone with a theoretical background might quibble with my choice of the word
“disallow”.  They might prefer that I say that certain operations in your
programming language are “invalid”.  In the world of mathematics, it’s usually
not the case that some little gremlin is actively preventing these operations
from occurring; instead, it’s that the invalid operations don’t even exist as
possibilities!&lt;/p&gt;

&lt;p&gt;But regardless what language you’re programming in, and regardless of whether
you think in terms of &lt;strong&gt;permissions&lt;/strong&gt; or &lt;strong&gt;possibilities&lt;/strong&gt;, the act of
programming is to consider all of these possible operations, and choose which
ones you want to use to accomplish your goal.  At any given time, there are many
possible operations, and you have the control to decide which ones to use!&lt;/p&gt;

&lt;p&gt;In this series of posts I want to look at the flip side of this, and talk about
&lt;strong&gt;requirements&lt;/strong&gt; or &lt;strong&gt;obligations&lt;/strong&gt;.  What mechanisms do programming languages
have to &lt;em&gt;force&lt;/em&gt; you to perform some operation, or to ensure that some operation
is performed even if you don’t actively choose to do it yourself?&lt;/p&gt;

&lt;p&gt;At the end of this series, I hope to convince you that obligations are just as
important as possibilities, and that there are interesting complex behaviors
that are easier to think about and work with if we use programming languages
that can talk about obligations directly.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2017-01-17:/hst/lazy-processes/</id>
    <title type="html">Lazy processes</title>
    <published>2017-01-17T00:00:00Z</published>
    <updated>2017-01-17T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/hst/lazy-processes/"/>
    <content type="html">
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      interleavesym: "|\\mkern-2mu|\\mkern-2mu|",
      interleave: "\\mathrel{\\interleavesym}",
    }
  }
});
&lt;/script&gt;

&lt;ol start="1" class="csp-algo-step"&gt;
  &lt;li&gt;Load in a description of the \(Spec\) and \(Impl\) processes,
transforming them each into a &lt;strong&gt;labeled transition system (LTS)&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As mentioned in the &lt;a href="/hst/semantic-methods/"&gt;previous post&lt;/a&gt;, we’re going to rely on
the &lt;em&gt;labeled transition system&lt;/em&gt; defined by CSP’s &lt;em&gt;operational semantics&lt;/em&gt; to
represent processes in our refinement checker.  An LTS is just a directed graph,
with nodes representing processes and subprocesses, and edges representing
events.  In this post, we’ll look at LTSes in a bit more detail, and at how best
to represent them in code.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-11-17:/hst/semantic-methods/</id>
    <title type="html">Semantic methods</title>
    <published>2016-11-17T14:00:00Z</published>
    <updated>2016-11-17T14:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/hst/semantic-methods/"/>
    <content type="html">
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      interleavesym: "|\\mkern-2mu|\\mkern-2mu|",
      interleave: "\\mathrel{\\interleavesym}",
      Interleave: "\\mathop{\\interleavesym}"
    }
  }
});
&lt;/script&gt;

&lt;p&gt;Since CSP is a formal method, it’s not surprising that Roscoe spends a large
part of his textbook talking about how to use rigorous mathematics to talk about
processes.  He actually goes one step (er, two?) further and defines &lt;strong&gt;three
different&lt;/strong&gt; ways to do so:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;denotational semantics&lt;/strong&gt; defines (mathematically, using sets and
sequences) what the &lt;em&gt;behavior&lt;/em&gt; of a process is.  Each CSP operator comes
with a rule for how to calculate a process’s behavior recursively — that is,
in terms of the behavior of its operands.  (So for example, the “external
choice” rule tells you how to define the behavior of \(P \mathrel{\Box}
Q\) in terms of the behavior of \(P\) and \(Q\).)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;algebraic semantics&lt;/strong&gt; tell you to not worry about what a process
“means” or what it “does”.  Instead, it provides a list of &lt;em&gt;rewrite rules&lt;/em&gt;
that let you change what the definition of a process looks like without
changing its behavior.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;operational semantics&lt;/strong&gt; say that a process is nothing more than a
state machine, with nodes representing processes (and subprocesses) and
edges representing the events that allow you to transition between them.  We
can learn anything important about a process just by interpreting or
analyzing this state machine.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-11-17:/hst/refinement-overview/</id>
    <title type="html">Refinement overview</title>
    <published>2016-11-17T13:00:00Z</published>
    <updated>2016-11-17T13:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/hst/refinement-overview/"/>
    <content type="html">
&lt;p&gt;Our goal is to learn about CSP refinement by implementing a refinement checker.
So a good first step is to make sure we’re all on the same page about what
refinement is, and then to step through the refinement algorithm that we mean to
implement.  (If nothing else, that will help make sure I don’t go off on too
many tangents while implementing it!)&lt;/p&gt;

&lt;p&gt;I’ve mentioned refinement elsewhere on this blog a few times (for instance,
&lt;a href="/csp-concurrency/read-atomic-internal/#refinement"&gt;here&lt;/a&gt;).  The basic idea is
that in CSP, you use the same process language to describe the system you’re
designing or investigating, as well as the properties that you would like that
system to have.  (This is unlike most other formal methods, where you have
separate languages for the system and the properties.)  In CSP, the system’s
process is typically called \(Impl\) (for &lt;strong&gt;implementation&lt;/strong&gt;), and the
property description process is typically called \(Spec\) (for
&lt;strong&gt;specification&lt;/strong&gt;).&lt;/p&gt;

&lt;p&gt;CSP then defines several &lt;strong&gt;semantic models&lt;/strong&gt; that provide rigorous mathematical
definitions of what a process’s behavior is.  You perform a refinement check
within the context of a particular semantic model.  A successful refinement
check tells you that the property defined by \(Spec\) “holds” — specifically,
that all of the behaviors of \(Impl\) are also allowed behaviors of
\(Spec\).  A failed refinement check gives you a &lt;strong&gt;counterexample&lt;/strong&gt; — that is,
a specific behavior of \(Impl\) that was disallowed by \(Spec\).&lt;/p&gt;

&lt;p&gt;The three most common semantic models are &lt;strong&gt;traces&lt;/strong&gt;, &lt;strong&gt;failures&lt;/strong&gt;, and
&lt;strong&gt;failures-divergences&lt;/strong&gt;.  We’ll go into more detail about the mathematics
behind these semantic models in later posts; for now, the 10,000-foot overview
is that:&lt;/p&gt;</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-11-16:/hst/intro/</id>
    <title type="html">Introduction</title>
    <published>2016-11-16T00:00:00Z</published>
    <updated>2016-11-16T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/hst/intro/"/>
    <content type="html">
&lt;p&gt;It seems like this blog is basically turning into “all things CSP”!  As part of
that trend, I’ve started implementing a new CSP refinement checker called
&lt;a href="https://github.com/hst/hst/"&gt;HST&lt;/a&gt;.  Why do this when there’s a perfectly good refinement checker in
&lt;a href="http://www.cs.ox.ac.uk/projects/fdr/"&gt;FDR&lt;/a&gt;?  Well, I want to learn more about how FDR’s refinement algorithm works.
The algorithm is documented in Bill Roscoe’s &lt;a href="https://www.cs.ox.ac.uk/bill.roscoe/publications/68b.pdf"&gt;textbook&lt;/a&gt; (and a series of
follow-on papers), and working through those descriptions gives you a good bit
of insight into how refinenment really works.  But I often find it easier to
learn a complex topic by implementing it (or at least, by looking at the code of
an implementation).  Hence HST!  In this new series of blog posts, I’m going to
walk through the CSP refinement algorithm in more detail than is presented in
the academic literature, by implementing it (and describing that implementation)
along the way.&lt;/p&gt;

&lt;p&gt;I should emphasize that this is &lt;strong&gt;not&lt;/strong&gt; meant to be a replacement for FDR!  FDR
is a very good piece of software, and if you’re writing any CSP specs in anger,
you probably want FDR at your disposal.  HST is meant to be more of an
educational exercise.  If people find it more generally useful than that, that’s
great!  But it’s not what I’m aiming for.&lt;/p&gt;

&lt;p&gt;(And as for the name, “HST” does &lt;em&gt;not&lt;/em&gt; stand for “Harry S. Truman”, just like
“FDR” does &lt;em&gt;not&lt;/em&gt; stand for “Franklin Delano Roosevelt”.)&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-09-07:/csp-concurrency/read-atomic-internal/</id>
    <title type="html">Read Atomic: Internal consistency</title>
    <published>2016-09-07T00:00:00Z</published>
    <updated>2016-09-07T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/csp-concurrency/read-atomic-internal/"/>
    <content type="html">
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      interleavesym: "|\\mkern-2mu|\\mkern-2mu|",
      interleave: "\\mathrel{\\interleavesym}",
      Interleave: "\\mathop{\\interleavesym}"
    }
  }
});
&lt;/script&gt;

&lt;p&gt;We’ll start by looking at the weakest concurrency model covered in the paper,
Read Atomic.  In fact, to keep things really simple to start with, we’re only
going to look at &lt;em&gt;one&lt;/em&gt; of Read Atomic’s two axioms: &lt;strong&gt;internal consistency&lt;/strong&gt;.
(We’ll look at external consistency in the next post.)&lt;/p&gt;

&lt;!--
 Read Atomic...can be implemented without requiring any coordination among
 replicas...a replica can decide to commit a transaction without consulting
 other replicas.
--&gt;

&lt;p&gt;A transaction is internally consistent if it “reads its own writes”.  This is
the simplest axiom covered in the paper, since it expresses a property that’s
strictly &lt;em&gt;local&lt;/em&gt; to each transaction; we don’t have to consider the behavior of
any other transaction when defining what it means for a transaction to be
internally consistent.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-08-03:/csp-concurrency/prelims/</id>
    <title type="html">Preliminaries</title>
    <published>2016-08-03T00:00:00Z</published>
    <updated>2016-08-03T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/csp-concurrency/prelims/"/>
    <content type="html">
&lt;p&gt;Before diving into the details of our first concurrency model, it will be
helpful to give an overview of how we’re going to use CSP in these posts.&lt;/p&gt;

&lt;p&gt;At the highest level, a CSP specification consists of a set of &lt;em&gt;processes&lt;/em&gt;,
which use &lt;em&gt;events&lt;/em&gt; to describe their behavior.  We use a process to represent
any vantage point that lets us talk about which events occur and in which order.
Each entity in our system is a process (which might be defined using
subprocesses to describe each of its components or parts).  We also use
processes to describe how two or more entities interact with each other, and to
describe any global properties of the entire system.  And lastly, because CSP
verification is based on “refinement”, we also use processes to define the
properties that we hope our system exhibits.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2016-07-28:/csp-concurrency/intro/</id>
    <title type="html">Introduction</title>
    <published>2016-07-28T00:00:00Z</published>
    <updated>2016-07-28T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/csp-concurrency/intro/"/>
    <content type="html">
&lt;p&gt;Two years ago, I started writing a series of &lt;a href="/2014/01/07/intro-to-csp/"&gt;blog&lt;/a&gt;
&lt;a href="/2014/02/csp-basics/"&gt;posts&lt;/a&gt; about CSP — Communicating Sequential Processes.
That series has…let’s say “stalled”.  Part of the reason is that I didn’t have
a good non-trivial example to work with.  The &lt;a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes#Examples"&gt;stereotypical running
example&lt;/a&gt;
is the vending machine: start with a simple one, which accepts a single coin and
spits out a tea; add more detail as you introduce more of the language.  I
always had a hunch that I needed an example with more meat on it, but could
never find one.&lt;/p&gt;

&lt;p&gt;Fast-forward to today.  I was reading through some of &lt;a href="https://christophermeiklejohn.com/"&gt;Christopher
Meiklejohn’s&lt;/a&gt; work on
&lt;a href="http://lasp-lang.org/"&gt;Lasp&lt;/a&gt;, I came across a citation to a really nice paper
by &lt;a href="http://drops.dagstuhl.de/opus/volltexte/2015/5375/"&gt;Cerone, Bernardi, and
Gotsman&lt;/a&gt;, which adds some
formal rigor to the consistency models that we use to describe modern
distributed systems.  Their formalism is a great combination of simple and
expressive.  The core of the paper is about processes accessing a transactional
data store; the authors provide formal definitions of several concurrency
models, and of some reference implementations that supposedly provide those
concurrency models.  They then use a technique called “observational refinement”
to show that the reference implementations really do provide the concurrency
guarantees in question.&lt;/p&gt;

&lt;p&gt;This approach lines up very well with how you perform refinement checks in CSP
to show that systems satisfy some specification.  And so I finally found my
meaty running example!  I’m resurrecting this blog series, and plan to work
through each of the consistency models and proofs described in the paper,
translating them into CSP processes and refinement checks.  This isn’t an
attempt to replace or outdo anything in the paper!  Far from it — it’s my
attempt to use something more familiar to work through the details of something
less familiar.&lt;/p&gt;

&lt;p&gt;I’m not going to assume a working knowledge of CSP — or of the consistency
models described in the paper!  If you’re familiar with one, my hope is that
you’ll be able to follow along and pick up the other.  And if you’re not
familiar with either…well, I guess we’ll see how good I am at writing an intro
to a difficult topic!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2014-11-21:/2014/11/dependency-management-in-c/</id>
    <title type="html">Dependency management in C</title>
    <published>2014-11-21T00:00:00Z</published>
    <updated>2014-11-21T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2014/11/dependency-management-in-c/"/>
    <content type="html">
&lt;p&gt;At &lt;a href="http://www.redjack.com/"&gt;RedJack&lt;/a&gt;, all of our &lt;a href="http://www.redjack.com/solutions/"&gt;core
products&lt;/a&gt; depend on a network sensor that
collects various bits of information about the raw traffic that we see on the
network.  We’re doing some non-trivial analysis on fairly large network links
using commodity hardware, so we’ve implemented this sensor in C.  At its core is
an extremely fast custom &lt;a href="http://en.wikipedia.org/wiki/Flow-based_programming"&gt;flow-based
programming&lt;/a&gt; framework.
It’s a damn cool piece of code, but this post isn’t about the code itself; it’s
about how we deliver that code to our customers.&lt;/p&gt;

&lt;p&gt;Just because we’ve written this component in C, that doesn’t mean we want to
turn our back on the kinds of tooling you get to use when working in other, more
modern languages.  In particular, once you’ve gotten used to modern package
managers like &lt;a href="https://www.npmjs.org/"&gt;npm&lt;/a&gt;, &lt;a href="http://leiningen.org/"&gt;leiningen&lt;/a&gt;,
&lt;a href="http://golang.org/doc/articles/go_command.html"&gt;go&lt;/a&gt;, and
&lt;a href="http://doc.crates.io/guide.html"&gt;Cargo&lt;/a&gt;, it’s hard to go back to things like
&lt;a href="http://www.cmake.org/"&gt;CMake&lt;/a&gt; and &lt;em&gt;[shudder]&lt;/em&gt; the
&lt;a href="http://en.wikipedia.org/wiki/GNU_build_system"&gt;autotools&lt;/a&gt;.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2014-05-14:/2014/05/git-flow/</id>
    <title type="html">Tagged releases using git flow</title>
    <published>2014-05-14T00:00:00Z</published>
    <updated>2014-05-14T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2014/05/git-flow/"/>
    <content type="html">
&lt;p&gt;I’ve used &lt;code&gt;git flow&lt;/code&gt; for most of my software projects — specifically for those
that have versioned releases.  The &lt;a href="http://nvie.com/posts/a-successful-git-branching-model/"&gt;original
post&lt;/a&gt; describing &lt;code&gt;git
flow&lt;/code&gt; is still the best overview of how it works.  In short, you have a &lt;code&gt;master&lt;/code&gt;
branch where &lt;strong&gt;every&lt;/strong&gt; commit is a merge commit.  Each of these merge commits
represents a new release, and is tagged with the version number of that release.
The merge brings in all of the subsidiary commits and feature branches that make
up that release.  Ongoing work happens on a separate &lt;code&gt;develop&lt;/code&gt; branch.  This is
where you merge in completed new features and bug fixes on a day-to-day basis.
&lt;code&gt;develop&lt;/code&gt; should always be a stable version of the software — you don’t merge a
feature branch into &lt;code&gt;develop&lt;/code&gt; until it passes all of your tests and is
“complete” with regards to the feature you’re trying to implement.&lt;/p&gt;

&lt;p&gt;My favorite part of this model is how each release is just some tagged commit on
the &lt;code&gt;master&lt;/code&gt; branch.  You want to see the code for the latest released version?
That’s easy — &lt;code&gt;git checkout master&lt;/code&gt;.  You want version 1.2.5 specifically?  Use
&lt;code&gt;git checkout 1.2.5&lt;/code&gt; instead.&lt;/p&gt;

&lt;p&gt;Unfortunately, the &lt;a href="https://github.com/nvie/gitflow"&gt;&lt;code&gt;git flow&lt;/code&gt; tool&lt;/a&gt; has
implemented a &lt;a href="https://github.com/nvie/gitflow/issues/206"&gt;slightly different
behavior&lt;/a&gt; for awhile now.  That
patch makes &lt;code&gt;git flow&lt;/code&gt; tag the last commit on the release branch, instead of the
merge commit on the &lt;code&gt;master&lt;/code&gt; branch.  The reasons for this might be perfectly
valid, but it’s not what I want, and it’s not what the original &lt;code&gt;git flow&lt;/code&gt; post
described.  That means that I can’t use &lt;code&gt;git flow release finish&lt;/code&gt; as-is.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2014-02-28:/2014/02/csp-basics/</id>
    <title type="html">CSP: The basics</title>
    <published>2014-02-28T00:00:00Z</published>
    <updated>2014-02-28T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2014/02/csp-basics/"/>
    <content type="html">
&lt;p class="big-def"&gt;&lt;em class="tldr"&gt;tl;dr&lt;/em&gt; CSP is a &lt;em&gt;formal method&lt;/em&gt; that lets you describe and reason
about the behavior of &lt;em&gt;concurrent systems&lt;/em&gt;.  CSP is &lt;em&gt;composable&lt;/em&gt;; you write
simple &lt;em&gt;processes&lt;/em&gt;, and then use special &lt;em&gt;operators&lt;/em&gt; to combine them together
into larger, more complex processes.  A process is a summary of some system; it
uses &lt;em&gt;events&lt;/em&gt; to describe how that system works, and to &lt;em&gt;synchronously
communicate&lt;/em&gt; with other processes.  You can compare two processes using a
&lt;em&gt;refinement check&lt;/em&gt;; this lets us check, for instance, whether a real-world
system satisfies some important safety or liveness property.  CSP has good &lt;em&gt;tool
support&lt;/em&gt;, which lets us perform these refinement checks quickly and
automatically.&lt;/p&gt;

&lt;p&gt;Well that was easy, wasn’t it?  You can boil just about anything down to a
single paragraph.  Let’s look at each of those key points in more detail.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2014-01-07:/2014/01/07/intro-to-csp/</id>
    <title type="html">CSP: An introduction</title>
    <published>2014-01-07T00:00:00Z</published>
    <updated>2014-01-07T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2014/01/07/intro-to-csp/"/>
    <content type="html">
&lt;p&gt;Communicating Sequential Processes (CSP) has been around for almost four decades
at this point, but for much of its life, it was only well-known among
theoretical computer scientists and formal methods advocates.  More recently,
many more people have at least &lt;em&gt;heard&lt;/em&gt; of CSP, largely because it inspired the
&lt;a href="http://golang.org/doc/effective_go.html#concurrency"&gt;concurrency support&lt;/a&gt; in
&lt;a href="http://golang.org/"&gt;Go&lt;/a&gt;, a popular mainstream programming language.  However,
if you ask most people what it &lt;em&gt;means&lt;/em&gt; to be inspired by CSP, the most common
response would probably be “erm, something about message passing”?&lt;/p&gt;

&lt;p&gt;That said, CSP isn’t just some dusty theory that inspired part of Go; it can
also help us understand the distributed systems that we create.  We’ve developed
a &lt;a href="http://zookeeper.apache.org/"&gt;plethora&lt;/a&gt; &lt;a href="http://www.mongodb.org/"&gt;of&lt;/a&gt;
&lt;a href="http://couchdb.apache.org/"&gt;tools&lt;/a&gt; &lt;a href="http://redis.io/"&gt;that&lt;/a&gt;
&lt;a href="http://basho.com/riak/"&gt;help&lt;/a&gt; &lt;a href="http://cassandra.apache.org/"&gt;us&lt;/a&gt;
&lt;a href="http://hbase.apache.org/"&gt;build&lt;/a&gt; &lt;a href="http://hadoop.apache.org/"&gt;distributed&lt;/a&gt;
&lt;a href="http://storm-project.net/"&gt;systems&lt;/a&gt;.  But unfortunately, we don’t always
understand of how those tools work, how they fail, and how they interact when we
piece them together into a larger system.  We can all name-drop the &lt;a href="http://dl.acm.org/citation.cfm?id=564601"&gt;CAP
theorem&lt;/a&gt;, but do you &lt;em&gt;really&lt;/em&gt; know
what your system is going to do when the network partitions, or when a host
dies?  How do you convince someone that you’re right?&lt;/p&gt;

&lt;p&gt;We can’t just rely on intuition and hand-wavy arguments; our systems are too
large, and too important, for that.  So how do you address these concerns with
rigor?  There are two main approaches: you can either &lt;em&gt;test&lt;/em&gt; your assumptions
empirically on a running system, or you can describe your system in detail and
&lt;em&gt;prove&lt;/em&gt; that your assumptions are correct.  Kyle Kingsbury has great examples of
both: &lt;a href="http://aphyr.com/tags/jepsen"&gt;Jepsen&lt;/a&gt; on the testing side,
&lt;a href="http://aphyr.com/posts/309-knossos-redis-and-linearizability"&gt;Knossos&lt;/a&gt; on the
proof side.  Both approaches are important; if you want to be convincing, you
have to choose at least one of them.  If you prefer the proof-based approach,
CSP is another option.  If you only think of CSP in terms of Go’s concurrency
primitives, or if you haven’t thought of it at all, then you overlook the fact
that CSP was &lt;em&gt;specifically designed&lt;/em&gt; to help answer these kinds of questions.&lt;/p&gt;

&lt;p&gt;In this series of articles, I want to describe how CSP fits into this landscape,
for developers with a range of expertise.  For the every-day programmer, I want
to give a basic, high-level introduction to CSP, and to explain what it means
for Go to be inspired by CSP.  For the distributed systems engineer, I want to
add weight to the argument that formal methods are a useful tool for studying
and designing the systems that we create and use.  And for the formal methodist,
I want to show how to use CSP in particular to specify and reason about those
systems.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2010-05-13:/2010/05/13/powerpc-qemu-lucid/</id>
    <title type="html">Installing Ubuntu Lucid on a PowerPC QEMU virtual machine</title>
    <published>2010-05-13T00:00:00Z</published>
    <updated>2010-05-13T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2010/05/13/powerpc-qemu-lucid/"/>
    <content type="html">
&lt;p&gt;Part of the software I help develop at
&lt;a href="http://www.redjack.com/"&gt;RedJack&lt;/a&gt; needs to be tested on both
little-endian and big-endian machines.  Little-endian machines are
easy, since everyone and their mother is running on a little-endian
Intel or AMD x86 chip.  It used to be that big-endian was pretty easy
to test, too — just break out your trusty Apple Powerbook G4 and
you’re good to go.  Since Apple has shifted over to Intel chips,
though, the situation has changed.&lt;/p&gt;

&lt;p&gt;Luckily, &lt;a href="http://wiki.qemu.org/"&gt;QEMU&lt;/a&gt; has PowerPC as one of the
targets that it can emulate, so in theory, I can still easily test my
code on a big-endian machine by creating a QEMU PowerPC virtual
machine.  There’s already a writeup about trying to install Debian
onto a QEMU VM
&lt;a href="http://machine-cycle.blogspot.com/2009/05/running-debian-on-qemu-powerpc.html"&gt;here&lt;/a&gt;.
&lt;a href="http://www.aurel32.net/"&gt;Aurélien Jarno&lt;/a&gt; has graciously put together
downloadable disk images with Debian preinstalled.  If that’s good
enough for your purposes, just go download those!  You won’t need any
of the rest of the information on this page.&lt;/p&gt;

&lt;p&gt;Unfortunately, I didn’t want to run stock Debian; my little-endian
build machine is running Ubuntu Lucid, and for consistency, I wanted
my big-endian VM to be running the same.  As it turns out, this also
required a fair dose of masochism on my part.  There are several
issues that you’ll encounter if you try to do this by hand.  Here is
my cheat sheet for getting around these issues.&lt;/p&gt;

&lt;p&gt;Note that this isn’t a full step-by-step account of how to install
Lucid onto a QEMU VM.  For now, I’m just trying to get my notes down
into a more permanent form.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2010-02-25:/2010/02/25/libpush-callbacks-part-1/</id>
    <title type="html">Parser callbacks in libpush, Part 1 — Streams</title>
    <published>2010-02-25T00:00:00Z</published>
    <updated>2010-02-25T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2010/02/25/libpush-callbacks-part-1/"/>
    <content type="html">
&lt;p&gt;This post is the first in a series that describes the
&lt;code&gt;push_callback_t&lt;/code&gt; type in the
&lt;a href="http://github.com/dcreager/libpush/"&gt;libpush&lt;/a&gt; library.  In these
posts, we’ll walk through a couple of possible ways to implement
callbacks under the covers.  At each stage, we’ll encounter problems
with the current design.  Fixing these problems should lead closer us
to the actual implementation in libpush, and along the way, we’ll gain
a good understanding of how our design decisions affect the
performance and usability of the library.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;push_callback_t&lt;/code&gt; type is used to define &lt;em&gt;parser callbacks&lt;/em&gt;, which
are the basic unit of parsing in libpush.  Callbacks are pretty
simple: they take in an &lt;em&gt;input value&lt;/em&gt;, read some data from the &lt;em&gt;input
stream&lt;/em&gt;, and produce an &lt;em&gt;output value&lt;/em&gt;.  (The fact that callbacks take
in an input value, in addition to reading from the input stream, is
what makes them &lt;a href="http://www.haskell.org/arrows/"&gt;&lt;em&gt;arrows&lt;/em&gt;&lt;/a&gt; instead of
&lt;a href="http://en.wikipedia.org/wiki/Monad_%28functional_programming%29"&gt;&lt;em&gt;monads&lt;/em&gt;&lt;/a&gt;
— but that’s a story for a later post).&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2010-02-17:/2010/02/17/llvm-lto-karmic/</id>
    <title type="html">Using LLVM's link-time optimization on Ubuntu Karmic</title>
    <published>2010-02-17T00:00:00Z</published>
    <updated>2010-02-17T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2010/02/17/llvm-lto-karmic/"/>
    <content type="html">
&lt;p&gt;While playing around with
&lt;a href="http://github.com/dcreager/libpush"&gt;libpush&lt;/a&gt; on my MacBook, I was
pleasantly surprised to see a huge performance increase when I used
the link-time optimization (LTO) feature of the LLVM GCC front end.
(It’s really quite nifty; the new &lt;a href="http://github.com/mxcl/homebrew"&gt;Homebrew package
manager&lt;/a&gt; uses it by default when
compiling packages.)  On MacOS, using LTO is as simple as using
&lt;code&gt;llvm-gcc&lt;/code&gt; as your C compiler (or &lt;code&gt;llvm-g++&lt;/code&gt; if you’re compiling C++),
and passing in &lt;code&gt;-O4&lt;/code&gt; as your optimization flag.  I use SCons as my
builder, so this turns into:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ scons CC=llvm-gcc CCFLAGS=-O4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will cause GCC to output LLVM bytecode into the &lt;em&gt;.o&lt;/em&gt; output
files, and to perform whole-program optimizations during each linking
phase.  I was able to see a big performance win simply from the linker
being able to inline in copies of small functions that live in “other”
compilation units.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2010-02-10:/2010/02/10/setuptools-git-version-numbers/</id>
    <title type="html">Extracting setuptools version numbers from your git repository</title>
    <published>2010-02-10T00:00:00Z</published>
    <updated>2010-02-10T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2010/02/10/setuptools-git-version-numbers/"/>
    <content type="html">
&lt;p&gt;Just like everyone else, we’re using
&lt;a href="http://pypi.python.org/pypi/setuptools"&gt;setuptools&lt;/a&gt; as the core of
the build system for our Python-based projects.  For the most part,
this has been a painless, straightforward process.  However, one
lingering annoyance is that we’ve been specifying the version number
directly in our &lt;em&gt;setup.py&lt;/em&gt; files:&lt;/p&gt;

&lt;pre class="CodeRay"&gt;&lt;code&gt;&lt;span class="keyword"&gt;from&lt;/span&gt; &lt;span class="include"&gt;setuptools&lt;/span&gt; &lt;span class="keyword"&gt;import&lt;/span&gt; &lt;span class="include"&gt;setup&lt;/span&gt;

setup(
    name = &lt;span class="string"&gt;&lt;span class="delimiter"&gt;&amp;quot;&lt;/span&gt;&lt;span class="content"&gt;awesomelib&lt;/span&gt;&lt;span class="delimiter"&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    version = &lt;span class="string"&gt;&lt;span class="delimiter"&gt;&amp;quot;&lt;/span&gt;&lt;span class="content"&gt;1.2&lt;/span&gt;&lt;span class="delimiter"&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class="comment"&gt;# ...etc&lt;/span&gt;
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On our maintenance branches, we get a nice &lt;em&gt;awesomelib-1.2.tar.gz&lt;/em&gt;
file when we run &lt;code&gt;python setup.py sdist&lt;/code&gt;.  On our development branch,
we’ve also got the following &lt;em&gt;setup.cfg&lt;/em&gt; file:&lt;/p&gt;

&lt;pre class="CodeRay"&gt;&lt;code&gt;[egg_info]
tag_build = dev
tag_date = true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That gives us tarballs like &lt;em&gt;awesomelib-1.2dev-20100210.tar.gz&lt;/em&gt; on our
development branch.  Because we’re using the &lt;code&gt;dev&lt;/code&gt; suffix, which
setuptools considers to be a “prerelease”, we have to remember to
increment the version number in development whenever we cut a new
release.  The end result is that we have a longish process for
creating releases.  If we want to create a new 1.3 release, we have to
do the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Create a new maintenance branch for 1.3:&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;$ git checkout -b maint-1.3 master
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Update the &lt;em&gt;setup.cfg&lt;/em&gt; file to remove the &lt;code&gt;tag_build&lt;/code&gt; and
&lt;code&gt;tag_date&lt;/code&gt; entries.  Commit this with a “Tagging version 1.3”
commit message.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Back on the development branch, update &lt;em&gt;setup.py&lt;/em&gt; to increment the
“development version” to 1.4.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Granted, this isn’t horribly difficult, but we can do better.&lt;/p&gt;

</content>
  </entry>
  <entry>
    <id>tag:dcreager.net,2010-02-06:/2010/02/06/libpush/</id>
    <title type="html">A combinator-based parsing library for C</title>
    <published>2010-02-06T00:00:00Z</published>
    <updated>2010-02-06T00:00:00Z</updated>
    <link rel="alternate" href="https://dcreager.net/2010/02/06/libpush/"/>
    <content type="html">
&lt;p&gt;Recently I’ve been working on
&lt;a href="http://github.com/dcreager/libpush/"&gt;libpush&lt;/a&gt;, which a new parsing
library for C.  It has two main features that I think will be
valuable: it’s a &lt;em&gt;push parser&lt;/em&gt;, which means that instead of parsing a
file, stream, or single memory buffer, you supply the data (or “push”
it) to the parser in chunks, as it becomes available.  I plan to
discuss this aspect of the parser in more detail in a later post.&lt;/p&gt;

&lt;p&gt;The other main feature is that you design your parsers using
&lt;em&gt;combinators&lt;/em&gt;.  Parser combinators are widely used in Haskell, with
&lt;a href="http://legacy.cs.uu.nl/daan/parsec.html"&gt;Parsec&lt;/a&gt; being the most
common example.  Combinator-based parsing libraries are especially
nice in Haskell, because Haskell’s syntax makes them look very simple.
For instance, a parser that parses matching nested parentheses is:&lt;/p&gt;

&lt;pre class="CodeRay"&gt;&lt;code&gt;parens :: Parser ()
parens = (char '(' &amp;gt;&amp;gt; parens &amp;gt;&amp;gt; char ')' &amp;gt;&amp;gt; parens) &amp;lt;|&amp;gt; return ()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, the &lt;code&gt;&amp;lt;|&amp;gt;&lt;/code&gt; operator represents &lt;em&gt;choice&lt;/em&gt;: we try parsing the left
operand, and if it fails, then we try the right operand.  In our
example, the right operand is the base case, which matches the empty
string.  The left operand parses an opening parenthesis; then
recursively calls itself to match any parentheses that might be nested
in the current set; then parses the closing parenthesis; and then
finally tries to match a nested set that occurs after the current set.&lt;/p&gt;</content>
  </entry>
</feed>

