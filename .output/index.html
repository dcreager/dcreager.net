<!doctype html>
<html lang="en">
<head>
    <title>
    dcreager.net – Home
  </title>
  <meta name="author" content="Douglas Creager">

    <meta charset="utf-8">

  <meta name="google-site-verification" content="7KIoYPNsfdDxIdX1QQ7SM2Nm_nyy13aRlDkzE3wzhhY" />

  <link rel="shortcut icon" href="/media/images/dcreager.ico">

  <link rel="alternate" type="application/atom+xml"
        title="dcreager.net" href="/atom.xml"/>

  <!-- Bootstrap -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel=stylesheet type=text/css media=screen
        href="/media/vendor/css/bootstrap.min.css">
  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
  <![endif]-->

  <!-- Customizations -->
  <link rel=stylesheet type=text/css media=screen
        href="/media/css/coderay.css">
  <link rel=stylesheet type=text/css media=screen
        href="/media/css/dcreager.css">
  <link rel=stylesheet type=text/css media=screen
        href="http://fonts.googleapis.com/css?family=Oxygen:400,700">

</head>

<body>
  <div class="container">
    <div class="row">
  <div class="col-md-10 col-md-offset-1">
    <nav class="navbar navbar-default" role="navigation">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="/"><b>dcreager.net</b></a>
      </div>

      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav navbar-right">
          <li><a href="/about/">About</a></li>
          <li><a href="/blog/all/">Archive</a></li>
          <li><a href="/publications/">Publications</a></li>
        </ul>
      </div><!-- /.navbar-collapse -->
    </nav>
  </div>
</div>

    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <ul class="summaries">

  
    <li class="summary">
      <div class="date">2010-05-13</div>
      <h1>Installing Ubuntu Lucid on a PowerPC QEMU virtual machine</h1>
      <p>Part of the software I help develop at
<a href="http://www.redjack.com/">RedJack</a> needs to be tested on both
little-endian and big-endian machines.  Little-endian machines are
easy, since everyone and their mother is running on a little-endian
Intel or AMD x86 chip.  It used to be that big-endian was pretty easy
to test, too — just break out your trusty Apple Powerbook G4 and
you're good to go.  Since Apple has shifted over to Intel chips,
though, the situation has changed.</p>

<p>Luckily, <a href="http://wiki.qemu.org/">QEMU</a> has PowerPC as one of the
targets that it can emulate, so in theory, I can still easily test my
code on a big-endian machine by creating a QEMU PowerPC virtual
machine.  There's already a writeup about trying to install Debian
onto a QEMU VM
<a href="http://machine-cycle.blogspot.com/2009/05/running-debian-on-qemu-powerpc.html">here</a>.
<a href="http://www.aurel32.net/">Aurélien Jarno</a> has graciously put together
downloadable disk images with Debian preinstalled.  If that's good
enough for your purposes, just go download those!  You won't need any
of the rest of the information on this page.</p>

<p>Unfortunately, I didn't want to run stock Debian; my little-endian
build machine is running Ubuntu Lucid, and for consistency, I wanted
my big-endian VM to be running the same.  As it turns out, this also
required a fair dose of masochism on my part.  There are several
issues that you'll encounter if you try to do this by hand.  Here is
my cheat sheet for getting around these issues.</p>

<p>Note that this isn't a full step-by-step account of how to install
Lucid onto a QEMU VM.  For now, I'm just trying to get my notes down
into a more permanent form.</p>


      <div class="link">
        <a href="/blog/2010-05-13-powerpc-qemu-lucid/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-02-25</div>
      <h1>Parser callbacks in libpush, Part 1 — Streams</h1>
      <p>This post is the first in a series that describes the
<code>push_callback_t</code> type in the
<a href="http://github.com/dcreager/libpush/">libpush</a> library.  In these
posts, we'll walk through a couple of possible ways to implement
callbacks under the covers.  At each stage, we'll encounter problems
with the current design.  Fixing these problems should lead closer us
to the actual implementation in libpush, and along the way, we'll gain
a good understanding of how our design decisions affect the
performance and usability of the library.</p>

<p>The <code>push_callback_t</code> type is used to define <em>parser callbacks</em>, which
are the basic unit of parsing in libpush.  Callbacks are pretty
simple: they take in an <em>input value</em>, read some data from the <em>input
stream</em>, and produce an <em>output value</em>.  (The fact that callbacks take
in an input value, in addition to reading from the input stream, is
what makes them <a href="http://www.haskell.org/arrows/"><em>arrows</em></a> instead of
<a href="http://en.wikipedia.org/wiki/Monad_%28functional_programming%29"><em>monads</em></a>
— but that's a story for a later post).</p>


      <div class="link">
        <a href="/blog/2010-02-25-libpush-callbacks-part-1/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-02-17</div>
      <h1>Using LLVM's link-time optimization on Ubuntu Karmic</h1>
      <p>While playing around with
<a href="http://github.com/dcreager/libpush">libpush</a> on my MacBook, I was
pleasantly surprised to see a huge performance increase when I used
the link-time optimization (LTO) feature of the LLVM GCC front end.
(It's really quite nifty; the new <a href="http://github.com/mxcl/homebrew">Homebrew package
manager</a> uses it by default when
compiling packages.)  On MacOS, using LTO is as simple as using
<code>llvm-gcc</code> as your C compiler (or <code>llvm-g++</code> if you're compiling C++),
and passing in <code>-O4</code> as your optimization flag.  I use SCons as my
builder, so this turns into:</p>

<pre><code>$ scons CC=llvm-gcc CCFLAGS=-O4
</code></pre>

<p>This will cause GCC to output LLVM bytecode into the <em>.o</em> output
files, and to perform whole-program optimizations during each linking
phase.  I was able to see a big performance win simply from the linker
being able to inline in copies of small functions that live in “other”
compilation units.</p>


      <div class="link">
        <a href="/blog/2010-02-17-llvm-lto-karmic/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-02-10</div>
      <h1>Extracting setuptools version numbers from your git repository</h1>
      <p>Just like everyone else, we're using
<a href="http://pypi.python.org/pypi/setuptools">setuptools</a> as the core of
the build system for our Python-based projects.  For the most part,
this has been a painless, straightforward process.  However, one
lingering annoyance is that we've been specifying the version number
directly in our <em>setup.py</em> files:</p>

<pre class="CodeRay"><code><span class="keyword">from</span> <span class="include">setuptools</span> <span class="keyword">import</span> <span class="include">setup</span>

setup(
    name = <span class="string"><span class="delimiter">&quot;</span><span class="content">awesomelib</span><span class="delimiter">&quot;</span></span>,
    version = <span class="string"><span class="delimiter">&quot;</span><span class="content">1.2</span><span class="delimiter">&quot;</span></span>,
    <span class="comment"># ...etc</span>
)
</code></pre>

<p>On our maintenance branches, we get a nice <em>awesomelib-1.2.tar.gz</em>
file when we run <code>python setup.py sdist</code>.  On our development branch,
we've also got the following <em>setup.cfg</em> file:</p>

<pre class="CodeRay"><code>[egg_info]
tag_build = dev
tag_date = true
</code></pre>

<p>That gives us tarballs like <em>awesomelib-1.2dev-20100210.tar.gz</em> on our
development branch.  Because we're using the <code>dev</code> suffix, which
setuptools considers to be a &quot;prerelease&quot;, we have to remember to
increment the version number in development whenever we cut a new
release.  The end result is that we have a longish process for
creating releases.  If we want to create a new 1.3 release, we have to
do the following:</p>

<ol>
<li><p>Create a new maintenance branch for 1.3:</p>

<pre><code>$ git checkout -b maint-1.3 master
</code></pre></li>
<li><p>Update the <em>setup.cfg</em> file to remove the <code>tag_build</code> and
<code>tag_date</code> entries.  Commit this with a &quot;Tagging version 1.3&quot;
commit message.</p></li>
<li><p>Back on the development branch, update <em>setup.py</em> to increment the
&quot;development version&quot; to 1.4.</p></li>
</ol>

<p>Granted, this isn't horribly difficult, but we can do better.</p>


      <div class="link">
        <a href="/blog/2010-02-10-setuptools-git-version-numbers/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-02-06</div>
      <h1>A combinator-based parsing library for C</h1>
      <p>Recently I've been working on
<a href="http://github.com/dcreager/libpush/">libpush</a>, which a new parsing
library for C.  It has two main features that I think will be
valuable: it's a <em>push parser</em>, which means that instead of parsing a
file, stream, or single memory buffer, you supply the data (or &quot;push&quot;
it) to the parser in chunks, as it becomes available.  I plan to
discuss this aspect of the parser in more detail in a later post.</p>

<p>The other main feature is that you design your parsers using
<em>combinators</em>.  Parser combinators are widely used in Haskell, with
<a href="http://legacy.cs.uu.nl/daan/parsec.html">Parsec</a> being the most
common example.  Combinator-based parsing libraries are especially
nice in Haskell, because Haskell's syntax makes them look very simple.
For instance, a parser that parses matching nested parentheses is:</p>

<pre class="CodeRay"><code>parens :: Parser ()
parens = (char '(' &gt;&gt; parens &gt;&gt; char ')' &gt;&gt; parens) &lt;|&gt; return ()
</code></pre>

<p>Here, the <code>&lt;|&gt;</code> operator represents <em>choice</em>: we try parsing the left
operand, and if it fails, then we try the right operand.  In our
example, the right operand is the base case, which matches the empty
string.  The left operand parses an opening parenthesis; then
recursively calls itself to match any parentheses that might be nested
in the current set; then parses the closing parenthesis; and then
finally tries to match a nested set that occurs after the current set.</p>
      <div class="link">
        <a href="/blog/2010-02-06-libpush/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-02-05</div>
      <h1>Updating graffle-export to work with OmniGraffle 5</h1>
      <p>I recently upgraded to OmniGraffle 5, which caused my
<a href="http://github.com/dcreager/graffle-export/">graffle-export</a> script to
break:</p>

<pre><code>$ graffle.sh ~/git/cwa/figures/analyst.graffle foo.pdf 
OmniGraffle Professional 5
/Users/dcreager/git/cwa/figures/analyst.graffle
./graffle.scpt: execution error: OmniGraffle Professional 5 got an error: The document cannot be exported to the &quot;pdf&quot; format. (-50)
</code></pre>

<p>(This was first reported to me by Nima Talebi as <a href="http://github.com/dcreager/graffle-export/issues/issue/1">a
ticket</a> on
graffle-export's Github page.)</p>

<p>Before we can understand what error we're seeing, a little explanation
is in order.  The core logic of the OmniGraffle exporter is an
AppleScript.  Unfortunately, AppleScripts are stored in a binary
format, so if you go to the Github page, you can't easily view the
contents of the file.  The important line of the script is:</p>
      <div class="link">
        <a href="/blog/2010-02-05-omnigraffle-5-export/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-01-08</div>
      <h1>Default “scons -c” targets</h1>
      <p>As I mentioned in a <a href="/2009/12/18/make-distclean-in-scons/">previous
post</a>, the automatic “clean”
target provided by SCons (<code>scons -c</code>) is very useful for cleaning out
build files, without requiring much in the way of configuration.
Anything that SCons generates when you run <code>scons</code> will be
automatically cleaned when you run <code>scons -c</code>.</p>

<p>While useful, I'd like more control over the behavior of <code>scons -c</code>.
Specifically, being a good TDD junkie, I have several test cases that
I can run using <code>scons test</code>:</p>

<pre class="highlight"><code class="language-python">
build_test = env.Program( ... )
env.Alias("build-tests", build_test)

run_test = env.Alias("test", [build_test],
                     ["@%s" % build_test[0].abspath])
env.AlwaysBuild(run_test)
</code></pre>

<p>By setting it up this way, the test programs aren't built by default:
you have to explicitly run <code>scons build-tests</code> (if you want to build
the tests but not run them) or <code>scons test</code> (if you want to build and
run them).  Moreover, because of SCons's dependency tracking, I can
just use <code>scons test</code> as my usual build command during my
Edit-Test-Debug loop.  SCons will automatically rebuild any changed
source files before running the tests.</p>

<p>All of this is great.  So what's the problem?  As I mentioned above,
<code>scons -c</code> only cleans the build files that are created by <code>scons</code> —
and since I've explicitly set things up so that tests aren't <em>built</em>
by default, they'll also not be <em>cleaned</em> by default.  This means that
to fully clean out my build targets, I have to run two commands:</p>

<pre><code>$ scons -c
$ scons -c build-tests
</code></pre>

<p>Not ideal!  I'd prefer if <code>scons -c</code> cleaned everything, just like
<code>make clean</code> would in the Automake world.</p>


      <div class="link">
        <a href="/blog/2010-01-08-default-scons-clean-targets/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2010-01-05</div>
      <h1>Exporting OmniGraffle documents from the command line</h1>
      <p><a href="http://www.omnigroup.com/applications/OmniGraffle/">OmniGraffle</a> is
my tool of choice for creating figures for my papers.  It's biggest
drawback is that it's only available for Mac OS, which can make it
cumbersome if I'm working on one of my Linux machines and need to
create or modify a figure.  But it's ease-of-use and the quality of
the figures it creates are hard to beat.</p>

<p>Of course, creating the figure isn't enough — since I write my papers
in LaTeX, I have to export my figures into EPS or PDF (depending on
whether I'm creating a PostScript or PDF version of the paper) before
I can use them in my documents.  It's easy enough to use the Export
dialog to do this (keyboard shortcut: ⌥⌘E), but ideally I'd like the
ability to export figures from the command line.  Coupled with a good
Makefile, this would let me run a simple <code>make paper</code> command, and
automatically re-export any necessary figures before rebuilding the
paper itself.</p>

<p>Luckily, OmniGraffle has always had rather good support for being
controlled via AppleScript.  The commands can be somewhat
undocumented, requiring a bit of trial and error, but while entrenched
in our PhD studies at Oxford, my colleague David Faitelson and I were
able to whip together a script that suited our needs.  I've recently
extracted the code from our Oxford SVN repository and uploaded it to
<a href="http://github.com/dcreager/graffle-export">Github</a>.</p>

<p>To install the script, just place the <em>graffle.sh</em> and <em>graffle.scpt</em>
files into some directory that's on your <code>$PATH</code>, such as
<em>/usr/local/bin</em> or <em>$HOME/bin</em>.  Then just run</p>
      <div class="link">
        <a href="/blog/2010-01-05-omnigraffle-export/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2009-12-23</div>
      <h1>“High-water mark” buffers</h1>
      <p>My coding project for today was to extract out some code for dealing
with “high-water mark buffers”, putting it in a separate library call
<code>libhwm</code>.  In this post, I'm going to describe the rationale for using
them, and a brief overview of how to use the library.  (The library is
hosted on <a href="http://github.com/dcreager/libhwm/">Github</a>).</p>

<p>By the way, this post (and the library) is all in C.</p>


      <div class="link">
        <a href="/blog/2009-12-23-high-water-mark-buffers/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  
    <li class="summary">
      <div class="date">2009-12-21</div>
      <h1>Decentralized datatypes</h1>
      <p>Over the past year or so there have been quite a few blog postings in
the REST world about MIME types, and their role in the REST
architecture.  A lot of the discussion seems to be prompted by WADL,
which is an attempt to define a WSDL-style interface description
language for REST services.  <a href="http://bitworking.org/news/193/Do-we-need-WADL">Joe
Gregorio</a> argues that
MIME types are more useful for describing the semantics of a service
than a WADL document, since there are parts of the service's semantics
that just can't be encoded in a machine-readable format.  MIME types
acknowledge this, providing a standard way of identifying a data
format and pointing to the human- and machine-readable documents (such
as RFCs and XSDs) that define the syntax and accompanying semantics.</p>

<p>Following this idea, several people have begun debating whether or not
the centralized assignment of MIME types is the right way to handle
the variety of data formats that REST-based systems produce and
consume.  <a href="http://www.markbaker.ca/blog/2008/02/media-type-centralization-is-a-feature-not-a-bug/">Mark
Baker</a>
comes in on the side of centralized assignment, whereas <a href="http://www.innoq.com/blog/st/2008/02/decentralizing_media_types.html">Stefan
Tilkov</a>,
<a href="http://netzooid.com/blog/2008/02/07/why-a-restful-idl-is-an-oxymoron-and-what-we-really-need-instead/">Dan
Diephouse</a>,
and <a href="http://macstrac.blogspot.com/2007/11/atompub-services-and-auto-detecting.html">James
Strachan</a>
argue in favor of decentralized types.  <a href="http://bill.burkecentral.com/2008/03/05/restful-xml-content-negotitation/">Bill
Burke</a>
and <a href="http://soundadvice.id.au/blog/2009/08/16/#mimeLimitation">Benjamin
Carlyle</a>
have good summaries of the different proposed technical solutions that
would enable decentralized types.</p>


      <div class="link">
        <a href="/blog/2009-12-21-decentralized-datatypes/">
          Continue reading <span class="glyphicon glyphicon-share-alt"></span>
        </a>
      </div>
    </li>
  

</ul>
      </div>
    </div> <!-- /row -->
  </div> <!-- /container -->

    <footer class="copyright">
    <div class="container">
      <p>Copyright © 2009-2013, Douglas Creager.
      All&nbsp;rights&nbsp;reserved.</p>
    </div>
  </footer>


  <script src="https://code.jquery.com/jquery.js"></script>
  <script src="/media/vendor/js/bootstrap.min.js"></script>

</html>
